# FedTPG Reproduction Study

**Paper**: Federated Text-driven Prompt Generation for Vision-Language Models (ICLR 2024)

**Authors**: Chen Qiu, Xingyu Li, Chaithanya Kumar Mummadi, et al.

**Original Repository**: [https://github.com/boschresearch/FedTPG](https://github.com/boschresearch/FedTPG)

---

## ğŸ“‹ Overview

This repository contains a reproduction study of FedTPG, evaluating the pre-trained model on 6 image classification datasets. Our study validates the paper's key claim that text-driven prompt generation enables effective generalization to unseen classes in federated learning settings.

## ğŸ¯ Key Results

| Metric | Value |
|--------|-------|
| **Base Classes Accuracy** | 74.47% |
| **New Classes Accuracy** | 76.23% |
| **Generalization Improvement** | +1.76% |

âœ… **Successfully validated**: FedTPG generalizes effectively to unseen classes

## ğŸ“Š Datasets Used

We evaluated on 6 out of 9 datasets from the original paper:

1. âœ… Caltech101 (97.2% base / 95.2% new)
2. âœ… Oxford Flowers (70.8% base / 78.7% new)
3. âœ… FGVC Aircraft (31.5% base / 35.7% new)
4. âœ… Oxford Pets (94.9% base / 94.5% new)
5. âœ… Food-101 (89.9% base / 91.6% new)
6. âœ… DTD (62.5% base / 61.7% new)

Missing datasets: UCF101, Stanford Cars, SUN397

## ğŸš€ Quick Start

### Prerequisites

```bash
conda create -n fedtpg python=3.10
conda activate fedtpg
pip install -r requirements.txt
```

### Download Datasets

Follow the instructions from [CoOp](https://github.com/KaiyangZhou/CoOp) to download and prepare the datasets.

### Run Evaluation

Using pre-trained weights (included in `output/cross_cls/fedtpg/20_8/43/`):

```bash
# Evaluate on 6 datasets
python evaluate_6_datasets.py --data-root ./data

# Or use the modified Launch_FL.py
python Launch_FL.py \
    --root ./data \
    --exp_name cross_cls \
    --model_name fedtpg \
    --eval-only \
    --model-dir output/cross_cls/fedtpg/20_8/43/ \
    --load-epoch 500
```

### Generate Visualizations

```bash
conda activate fedtpg
python create_visualizations.py
```

This creates:
- `visualizations/base_vs_new_comparison.png`
- `visualizations/generalization_gap.png`
- `visualizations/method_comparison.png`
- `visualizations/performance_heatmap.png`
- `visualizations/results_table.png`
- `visualizations/architecture_overview.png`

### Parse Results

```bash
python parse_results.py
```

Generates:
- `evaluation_results/comparison_table_6datasets.csv`
- `evaluation_results/extracted_results.json`

## ğŸ“ Repository Structure

```
FedTPG/
â”œâ”€â”€ clip/                           # CLIP model implementation
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ defaults.py                # Default configurations
â”‚   â””â”€â”€ utils.py                   # Config utilities (modified for 6 datasets)
â”œâ”€â”€ dataloader/                     # Data loading utilities
â”œâ”€â”€ federated/                      # Federated learning implementation
â”‚   â”œâ”€â”€ server.py                  # FL server
â”‚   â”œâ”€â”€ client.py                  # FL client
â”‚   â””â”€â”€ base_trainer.py            # Training logic
â”œâ”€â”€ model/                          # Model architectures
â”‚   â”œâ”€â”€ FedTPG.py                  # FedTPG implementation
â”‚   â”œâ”€â”€ custom_coop.py             # CoOp baseline
â”‚   â””â”€â”€ prompt_net.py              # Prompt generation network
â”œâ”€â”€ output/                         # Pre-trained models
â”‚   â””â”€â”€ cross_cls/fedtpg/20_8/43/
â”‚       â”œâ”€â”€ log.txt                # Training logs
â”‚       â””â”€â”€ prompt_learner/
â”‚           â””â”€â”€ model.pth.tar-500  # Pre-trained weights
â”œâ”€â”€ data/                           # Datasets (download separately)
â”œâ”€â”€ reproduction_report/            # LaTeX report
â”‚   â””â”€â”€ fedtpg_reproduction.tex
â”œâ”€â”€ visualizations/                 # Generated figures
â”œâ”€â”€ evaluation_results/             # Evaluation outputs
â”œâ”€â”€ Launch_FL.py                    # Main training/evaluation script
â”œâ”€â”€ evaluate_6_datasets.py          # Simplified evaluation script
â”œâ”€â”€ create_visualizations.py        # Visualization generation
â”œâ”€â”€ parse_results.py                # Results parsing
â”œâ”€â”€ RESULTS_SUMMARY.md              # Detailed results
â”œâ”€â”€ REPRODUCTION_README.md          # This file
â””â”€â”€ requirements.txt                # Python dependencies
```

## ğŸ”¬ Methodology

### FedTPG Architecture

1. **Prompt Generation Network**: Learns to generate text prompts conditioned on class names
2. **Text Encoder**: Frozen CLIP text encoder processes generated prompts
3. **Image Encoder**: Frozen ViT-B/16 extracts visual features
4. **Federated Training**: Clients train locally and aggregate via FedAvg

### Key Hyperparameters

- **Backbone**: ViT-B/16
- **Shots**: 8 per class
- **Classes per client**: 20
- **Context tokens**: 4
- **Context depth**: 1
- **Training epochs**: 500
- **Batch size**: 200
- **Optimizer**: SGD (momentum=0.9, lr=0.003)
- **LR scheduler**: Cosine annealing

## ğŸ“ˆ Detailed Results

### Per-Dataset Performance

| Dataset | Base Acc (%) | New Acc (%) | Î” (%) | Samples (Base) | Samples (New) |
|---------|--------------|-------------|-------|----------------|---------------|
| Caltech101 | 97.2 | 95.2 | -2.0 | 1,549 | 916 |
| Oxford Flowers | 70.8 | 78.7 | **+7.9** | 1,053 | 1,410 |
| FGVC Aircraft | 31.5 | 35.7 | +4.2 | 1,666 | 1,667 |
| Oxford Pets | 94.9 | 94.5 | -0.4 | 1,881 | 1,788 |
| Food-101 | 89.9 | 91.6 | +1.7 | 15,300 | 15,000 |
| DTD | 62.5 | 61.7 | -0.8 | 864 | 828 |
| **Average** | **74.47** | **76.23** | **+1.76** | - | - |

### Key Observations

âœ… **Strong base performance**: Average 74.47% on seen classes

âœ… **Effective generalization**: +1.76% improvement on unseen classes

âœ… **Best generalization**: Oxford Flowers (+7.9%) and FGVC Aircraft (+4.2%)

âš ï¸ **Challenging tasks**: Fine-grained recognition (Aircraft: 31-36%)

## ğŸ“ Reproduction Report

The full reproduction report is available as:
- **LaTeX**: `reproduction_report/fedtpg_reproduction.tex`
- **PDF**: Compile with `pdflatex` or `overleaf`

### Compiling the Report

```bash
cd reproduction_report
pdflatex fedtpg_reproduction.tex
bibtex fedtpg_reproduction
pdflatex fedtpg_reproduction.tex
pdflatex fedtpg_reproduction.tex
```

## ğŸ¥ Demo Video

[Link to presentation/demo video will be added]

**Contents**:
1. Problem introduction and motivation
2. FedTPG architecture overview
3. Evaluation process demonstration
4. Results visualization and analysis
5. Key insights and conclusions

## ğŸ“ Citation

Original paper:

```bibtex
@inproceedings{qiu2024fedtpg,
  title={Federated Text-driven Prompt Generation for Vision-Language Models},
  author={Qiu, Chen and Li, Xingyu and Mummadi, Chaithanya Kumar and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}
```

This reproduction study:

```bibtex
@misc{fedtpg_reproduction2024,
  title={Reproduction Study: Federated Text-driven Prompt Generation for Vision-Language Models},
  author={[Your Name]},
  year={2024},
  howpublished={GitHub Repository},
  url={[Your GitHub URL]}
}
```

## ğŸ”— Links

- ğŸ“„ **Original Paper**: [OpenReview](https://openreview.net/forum?id=NW31gAylIm)
- ğŸ’» **Original Code**: [GitHub](https://github.com/boschresearch/FedTPG)
- ğŸ“Š **ArXiv**: [2310.06123](https://arxiv.org/abs/2310.06123)

## ğŸ¤ Acknowledgments

- Original FedTPG authors: Chen Qiu et al. @ Bosch Research
- CoOp framework: Kaiyang Zhou et al.
- CLIP model: OpenAI

## ğŸ“§ Contact

For questions about this reproduction:
- Email: [Your Email]
- GitHub Issues: [Your Repo Issues]

## ğŸ“œ License

This reproduction study follows the same license as the original FedTPG repository (AGPL-3.0).

---

**Last Updated**: November 2024
